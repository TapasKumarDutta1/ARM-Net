{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seeing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/gan_segmentation_FE/blob/main/seeing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttofd7ZxZ-rI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz-6SdBpaC4a"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channel=512):\n",
        "        super(Discriminator, self).__init__()        \n",
        "        self.channel = channel\n",
        "        n_class = 1\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1, channel//8, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channel//8, channel//4, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(channel//4)\n",
        "        self.conv3 = nn.Conv3d(channel//4, channel//2, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm3d(channel//2)\n",
        "        self.conv4 = nn.Conv3d(channel//2, channel, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm3d(channel)\n",
        "        \n",
        "        self.conv5 = nn.Conv3d(channel, n_class, kernel_size=4, stride=2, padding=1)\n",
        "        \n",
        "    def forward(self, x, _return_activations=False):\n",
        "        h1 = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
        "        h2 = F.leaky_relu(self.bn2(self.conv2(h1)), negative_slope=0.2)\n",
        "        h3 = F.leaky_relu(self.bn3(self.conv3(h2)), negative_slope=0.2)\n",
        "        h4 = F.leaky_relu(self.bn4(self.conv4(h3)), negative_slope=0.2)\n",
        "        h5 = self.conv5(h4)\n",
        "        output = h5\n",
        "\n",
        "        return output\n",
        "    \n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise:int=1000, channel:int=64):\n",
        "        super(Generator, self).__init__()\n",
        "        _c = channel\n",
        "        \n",
        "        self.noise = noise\n",
        "        self.fc = nn.Linear(1000,512*4*4*4)\n",
        "        self.fc.requires_grad_=False\n",
        "        self.bn1 = nn.BatchNorm3d(_c*8)\n",
        "        self.bn1.requires_grad_=False\n",
        "        \n",
        "        self.tp_conv2 = nn.Conv3d(_c*8, _c*4, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.tp_conv2.requires_grad_=False\n",
        "        self.bn2 = nn.BatchNorm3d(_c*4)\n",
        "        self.bn2.requires_grad_=False\n",
        "        \n",
        "        self.tp_conv3 = nn.Conv3d(_c*4, _c*2, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(_c*2)\n",
        "        \n",
        "        self.tp_conv4 = nn.Conv3d(_c*2, _c, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm3d(_c)\n",
        "        \n",
        "        self.tp_conv5 = nn.Conv3d(_c, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        \n",
        "    def forward(self, noise):\n",
        "        noise = noise.view(-1, 1000)\n",
        "        h = self.fc(noise)\n",
        "        h = h.view(-1,512,4,4,4)\n",
        "        h = F.relu(self.bn1(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv2(h)\n",
        "        h = F.relu(self.bn2(h))\n",
        "        \n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv3(h)\n",
        "        h = F.relu(self.bn3(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv4(h)\n",
        "        h = F.relu(self.bn4(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv5(h)\n",
        "\n",
        "        h = F.tanh(h)\n",
        "\n",
        "        return h\n",
        "g=torch.load('/content/gdrive/MyDrive/generator_199.pth',map_location='cpu')\n",
        "G1 = Generator()\n",
        "\n",
        "G1.load_state_dict(g['model_state_dict'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRx00hxyGjI6"
      },
      "source": [
        "\n",
        "from skimage.transform import resize\n",
        "img_deps=512\n",
        "img_rows=512\n",
        "img_cols=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et8LAlBMb4oH"
      },
      "source": [
        "import gc\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(28)):\n",
        "  noise = torch.randn((1, 1000, 1, 1, 1))\n",
        "  fake_images = G1(noise)\n",
        "  fake_images=fake_images[0,0].detach().numpy()\n",
        "  img=np.round(fake_images[:,:,:32]*255)\n",
        "  livertumor=np.round(fake_images[:,:,32:]*2)\n",
        "  livertumor[livertumor<0]=0\n",
        "  img[img < -200] = -200\n",
        "  img[img > 250] = 250\n",
        "  img = np.array(img, dtype='float32')\n",
        "  cropp_tumor = resize(livertumor, (img_deps,img_rows,img_cols), order=0, mode='edge', cval=0, clip=True, preserve_range=True)\n",
        "  cropp_img   = resize(img, (img_deps,img_rows,img_cols), order=3, mode='constant', cval=0, clip=True, preserve_range=True)\n",
        "  np.save('/content/gdrive/MyDrive/test_'+str(i)+'.npy',[cropp_tumor,cropp_img])\n",
        "  del([noise,fake_images,img,livertumor,cropp_tumor,cropp_img])\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALpc3OKUcd1s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}