{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import scipy.io\n",
    "from imgaug import augmenters as iaa\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.activations import *\n",
    "lbl=[]\n",
    "img=np.zeros((3064,224,224))\n",
    "for i in range(1,3065):\n",
    "    try:\n",
    "        path='/kaggle/input/brain-tumour/brainTumorDataPublic_1766/'\n",
    "        with h5py.File(path+str(i)+'.mat') as f:\n",
    "          images = f['cjdata']\n",
    "          resized = cv2.resize(images['image'][:,:], (224,224), interpolation = cv2.INTER_CUBIC )\n",
    "          x=np.asarray(resized)\n",
    "          x=(x-np.min(x))/(np.max(x)-np.min(x))\n",
    "          x=x.reshape((1,224,224))\n",
    "          img[i-1]=x\n",
    "          lbl.append(int(images['label'][0]))\n",
    "    except:\n",
    "        try:\n",
    "          path='/kaggle/input/brain-tumour/brainTumorDataPublic_22993064/'\n",
    "          with h5py.File(path+str(i)+'.mat') as f:\n",
    "              images = f['cjdata']\n",
    "              resized = cv2.resize(images['image'][:,:], (224,224), interpolation = cv2.INTER_CUBIC )\n",
    "              x=np.asarray(resized)\n",
    "              x=(x-np.min(x))/(np.max(x)-np.min(x))\n",
    "              x=x.reshape((1,224,224))\n",
    "              img[i-1]=x\n",
    "              lbl.append(int(images['label'][0]))\n",
    "        except:\n",
    "            try:\n",
    "              path='/kaggle/input/brain-tumour/brainTumorDataPublic_15332298/'\n",
    "              with h5py.File(path+str(i)+'.mat') as f:\n",
    "                  images = f['cjdata']\n",
    "                  resized = cv2.resize(images['image'][:,:], (224,224), interpolation = cv2.INTER_CUBIC )\n",
    "                  x=np.asarray(resized)\n",
    "                  x=(x-np.min(x))/(np.max(x)-np.min(x))\n",
    "                  x=x.reshape((1,224,224))\n",
    "                  img[i-1]=x\n",
    "                  lbl.append(int(images['label'][0]))\n",
    "            except:\n",
    "              path='/kaggle/input/brain-tumour/brainTumorDataPublic_7671532/'\n",
    "              with h5py.File(path+str(i)+'.mat') as f:\n",
    "                  images = f['cjdata']\n",
    "                  resized = cv2.resize(images['image'][:,:], (224,224), interpolation = cv2.INTER_CUBIC )\n",
    "                  x=np.asarray(resized)\n",
    "                  x=(x-np.min(x))/(np.max(x)-np.min(x))\n",
    "                  x=x.reshape((1,224,224))\n",
    "                  img[i-1]=x\n",
    "                  lbl.append(int(images['label'][0]))\n",
    "\n",
    "path='/kaggle/input/braintumour/cvind (2).mat'\n",
    "\n",
    "with h5py.File(path) as f:\n",
    "      data=f['cvind']\n",
    "      idx=data[0]\n",
    "obj_arr = {}\n",
    "obj_arr['images'] = img\n",
    "obj_arr['label'] = lbl\n",
    "obj_arr['fold']=idx\n",
    "np.save('check.npy', obj_arr)\n",
    "path = \"check.npy\"\n",
    "\n",
    "def Global_attention_block(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    x=Lambda(lambda x: K.mean(x,-1))(inputs)\n",
    "    x=Reshape((1,-1))(x)\n",
    "    x=sigmoid(x)# 1,HW\n",
    "    \n",
    "    y=Reshape((-1,shape[-1]))(inputs)#HW C\n",
    "    \n",
    "    x=K.batch_dot(x,y)#1 C\n",
    "    \n",
    "    p=GlobalAveragePooling2D() (inputs)\n",
    "    p=Reshape((1,1,shape[-1]))(p)#1 1 C\n",
    "    p=Conv2D(shape[-1],1,activation='relu')(p)\n",
    "    p=Conv2D(shape[-1],1,activation='sigmoid')(p)\n",
    "    p=Reshape((1,shape[-1]))(p)#1 C\n",
    "    \n",
    "    \n",
    "    x=Concatenate()([x,p])\n",
    "    x=Reshape((1,1,2*shape[-1]))(x)#1 1 C\n",
    "    x=Conv2D(shape[-1],1,activation='sigmoid')(x)\n",
    "    \n",
    "    return Multiply()([x,inputs])\n",
    "\n",
    "\n",
    "def load_model():   \n",
    "  K.clear_session() \n",
    "  mod1=DenseNet121(input_shape=(224,224,3))\n",
    "  out_1=mod1.layers[-3].output\n",
    "  p=Lambda(lambda x: x[:,:,:, :512])(out_1)\n",
    "  q=Lambda(lambda x: x[:,:,:, 512:])(out_1)\n",
    "    \n",
    "  p = Global_attention_block(p)\n",
    "  q = Global_attention_block(q)\n",
    "  \n",
    "  out_1=Concatenate()([p,q])\n",
    "  out_1 = GlobalAveragePooling2D()(out_1)\n",
    "  out=Dense(3,activation='softmax')(out_1)\n",
    "  model=Model(inputs=mod1.input,outputs=out)\n",
    "  return model\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "def get_trn_tst(df,tst_fold):\n",
    "  idx=np.asarray(df['fold'])\n",
    "  y=np.asarray(df['label'])\n",
    "  y-=1\n",
    "  img=np.asarray(df['images'])\n",
    "  img1=[]\n",
    "  for i in range(len(img)):\n",
    "        img1.append(change(img[i]))\n",
    "  img1=np.asarray(img1)\n",
    "  del([img])\n",
    "  gc.collect()\n",
    "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
    "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
    "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
    "  tst_img=img1[idx==tst_fold]\n",
    "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],224,224,1)),3,axis=3)\n",
    "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],224,224,1)),3,axis=3)\n",
    "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())\n",
    "\n",
    "def change(img):\n",
    "    resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA )\n",
    "    return resized\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "  return result\n",
    "def Hflip( images):\n",
    "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
    "\t\treturn seq.augment_images(images)\n",
    "def Vflip( images):\n",
    "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
    "\t\treturn seq.augment_images(images)\n",
    "def noise(images):\n",
    "    ls=[]\n",
    "    for i in images:\n",
    "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
    "        ls.append(i+x)\n",
    "    return ls\n",
    "def rotate(images):\n",
    "    ls=[]\n",
    "    for angle in range(-15,20,5):\n",
    "        for image in images:\n",
    "            ls.append(rotate_image(image,angle))\n",
    "    return ls\n",
    "class DataGenerator(Sequence):\n",
    "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
    "    self.labels       = labels              # array of labels\n",
    "    self.images = images        # array of image paths\n",
    "    self.batch_size   = batch_size          # batch size\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(self.labels.shape[0])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "    labels = self.labels.loc[indexes]\n",
    "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
    "    imgH=Hflip(img)\n",
    "    imgV=Vflip(img)\n",
    "    imgR=rotate(img)\n",
    "    images=[]\n",
    "    images.extend(imgH)\n",
    "    images.extend(imgV)\n",
    "    images.extend(imgR)\n",
    "    lbl=labels.copy()\n",
    "    labels=pd.DataFrame()\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    labels=pd.concat([labels,lbl],0)\n",
    "    return np.asarray(images), np.asarray(labels.values)\n",
    "def upd(dk,data):\n",
    "  if dk==0:\n",
    "    dk=data\n",
    "  else:\n",
    "    for ky in data.keys():\n",
    "      dk[ky].extend(data[ky])\n",
    "  return dk\n",
    "def train(index):\n",
    "  df=np.load(path,allow_pickle=True)\n",
    "  df=df.item()\n",
    "  epoch=50\n",
    "  fold='fold_'+str(index)\n",
    "  trn,tst=get_trn_tst(df,index)\n",
    "  model=load_model()\n",
    "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
    "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=4, augment=True)\n",
    "  ln=len(trn_y)\n",
    "  model.compile(optimizer=Adam(2e-4,decay=1e-3), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "  hist=model.fit_generator(train_data,epochs=50,verbose=1,steps_per_epoch=ln//4)\n",
    "  \n",
    "index=1\n",
    "train(index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
